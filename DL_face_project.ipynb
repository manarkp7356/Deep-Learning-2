{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594cb105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Mediapipe setup\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=False,\n",
    "    max_num_faces=5,  # Allow up to 5 faces\n",
    "    refine_landmarks=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdbdcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "drawing_utils = mp.solutions.drawing_utils\n",
    "LIPS = mp_face_mesh.FACEMESH_LIPS\n",
    "LEFT_IRIS = [468, 469, 470, 471]\n",
    "RIGHT_IRIS = [473, 474, 475, 476]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01826cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion settings\n",
    "emotions = {\n",
    "    \"happy\": {\"emoji\": \"ğŸ˜Š\", \"color\": (0, 255, 0)},\n",
    "    \"sad\": {\"emoji\": \"ğŸ˜¢\", \"color\": (255, 0, 0)},\n",
    "    \"angry\": {\"emoji\": \"ğŸ˜ \", \"color\": (0, 0, 255)},\n",
    "    \"surprise\": {\"emoji\": \"ğŸ˜²\", \"color\": (0, 255, 255)},\n",
    "    \"neutral\": {\"emoji\": \"ğŸ˜\", \"color\": (255, 255, 255)},\n",
    "    \"fear\": {\"emoji\": \"ğŸ˜¨\", \"color\": (255, 140, 0)},\n",
    "    \"disgust\": {\"emoji\": \"ğŸ¤¢\", \"color\": (138, 43, 226)}\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a548fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(p1, p2):\n",
    "    return np.linalg.norm(np.array([p1.x, p1.y]) - np.array([p2.x, p2.y]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425100be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion(landmarks):\n",
    "    top_lip = landmarks[13]\n",
    "    bottom_lip = landmarks[14]\n",
    "    left_mouth = landmarks[61]\n",
    "    right_mouth = landmarks[291]\n",
    "    left_eye_top = landmarks[159]\n",
    "    left_eye_bottom = landmarks[145]\n",
    "    right_eye_top = landmarks[386]\n",
    "    right_eye_bottom = landmarks[374]\n",
    "    iris_left = landmarks[468]\n",
    "\n",
    "    face_width = distance(landmarks[234], landmarks[454])\n",
    "    mouth_open = distance(top_lip, bottom_lip) / face_width\n",
    "    mouth_stretch = distance(left_mouth, right_mouth) / face_width\n",
    "    eye_open = (distance(left_eye_top, left_eye_bottom) + distance(right_eye_top, right_eye_bottom)) / (2 * face_width)\n",
    "    \n",
    "    eye_center_y = (left_eye_top.y + left_eye_bottom.y + right_eye_top.y + right_eye_bottom.y) / 4\n",
    "    sad_offset = iris_left.y - eye_center_y\n",
    "\n",
    "    if mouth_stretch > 0.40 and mouth_open < 0.06:\n",
    "        return \"happy\"\n",
    "    elif mouth_open >= 0.12:\n",
    "        return \"surprise\"\n",
    "    elif 0.06 < mouth_open < 0.12:\n",
    "        return \"fear\"\n",
    "    elif sad_offset > 0.01 and eye_open < 0.04:\n",
    "        return \"sad\"\n",
    "    elif mouth_open < 0.03 and eye_open < 0.08 and mouth_stretch < 0.38:\n",
    "        return \"disgust\"\n",
    "    elif eye_open > 0.096 and mouth_open < 0.06:\n",
    "        return \"angry\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ad1290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webcam loop\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, _ = frame.shape\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb)\n",
    "    avatar_canvas = np.zeros_like(frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            landmark_list = face_landmarks.landmark\n",
    "            emotion = get_emotion(landmark_list)\n",
    "            color = emotions[emotion][\"color\"]\n",
    "            emoji = emotions[emotion][\"emoji\"]\n",
    "\n",
    "            # Draw mesh and lips\n",
    "            drawing_utils.draw_landmarks(\n",
    "                avatar_canvas, face_landmarks,\n",
    "                mp_face_mesh.FACEMESH_TESSELATION, None,\n",
    "                drawing_utils.DrawingSpec(color=color, thickness=1, circle_radius=1)\n",
    "            )\n",
    "            drawing_utils.draw_landmarks(\n",
    "                avatar_canvas, face_landmarks, LIPS, None,\n",
    "                drawing_utils.DrawingSpec(color=(0, 255, 0), thickness=1, circle_radius=1)\n",
    "            )\n",
    "\n",
    "            # Draw iris\n",
    "            for idx in LEFT_IRIS + RIGHT_IRIS:\n",
    "                pt = landmark_list[idx]\n",
    "                cx, cy = int(pt.x * w), int(pt.y * h)\n",
    "                cv2.circle(avatar_canvas, (cx, cy), 2, (0, 255, 255), -1)\n",
    "\n",
    "            # Draw emotion near face\n",
    "            cx, cy = int(landmark_list[0].x * w), int(landmark_list[0].y * h)\n",
    "            cv2.putText(avatar_canvas, f\"{emotion.upper()} {emoji}\", (cx - 50, cy - 20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "    # Show both webcam and emotion mesh\n",
    "    cv2.imshow(\"Webcam Feed\", cv2.resize(frame, (640, 480)))\n",
    "    cv2.imshow(\"Avatar Emotion Mesh\", cv2.resize(avatar_canvas, (640, 480)))\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # ESC key to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
